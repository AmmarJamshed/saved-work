{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPT6M61ApFokveZ13qIuq3L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmmarJamshed/saved-work/blob/main/ML_EDu_enrollment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkEt1ISnMv6l"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# POC Framework of EDX dataset for online education platforms in Pakistan with similar features in their datasets."
      ],
      "metadata": {
        "id": "6PFdZmj2oUWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Edx Data and we choose selected features which we believe are present in online platforms in Pakistan too which are:\n",
        "\n",
        "['length', 'price', 'Level', 'subject', 'course_type']"
      ],
      "metadata": {
        "id": "m3uVRgJZBOL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Edx dataset\n",
        "df = pd.read_csv('/content/edx_courses.csv')\n",
        "\n",
        "# Displaying first few rows of the dataset\n",
        "print(df.head())\n",
        "\n",
        "# Selecting relevant features for prediction\n",
        "# Assume these columns exist in the dataset based on your description\n",
        "features = ['course_length', 'price', 'Level', 'subject', 'course_type']\n",
        "target = 'n_enrolled'  # This is the target variable we're predicting\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0wh35-SNzUm",
        "outputId": "b6f38ce5-9214-441c-eed6-ea59102d0bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  \\\n",
            "0                                How to Learn Online   \n",
            "1  Programming for Everybody (Getting Started wit...   \n",
            "2            CS50's Introduction to Computer Science   \n",
            "3                                 The Analytics Edge   \n",
            "4  Marketing Analytics: Marketing Measurement Str...   \n",
            "\n",
            "                                             summary n_enrolled  \\\n",
            "0  Learn essential strategies for successful onli...    124,980   \n",
            "1  This course is a \"no prerequisite\" introductio...    293,864   \n",
            "2  An introduction to the intellectual enterprise...  2,442,271   \n",
            "3  Through inspiring examples and stories, discov...    129,555   \n",
            "4     This course is part of a MicroMasters® Program     81,140   \n",
            "\n",
            "                           course_type                            institution  \\\n",
            "0              Self-paced on your time                                    edX   \n",
            "1              Self-paced on your time             The University of Michigan   \n",
            "2              Self-paced on your time                     Harvard University   \n",
            "3  Instructor-led on a course schedule  Massachusetts Institute of Technology   \n",
            "4              Self-paced on your time     University of California, Berkeley   \n",
            "\n",
            "                                         instructors         Level  \\\n",
            "0            Nina Huntemann-Robyn Belair-Ben Piscopo  Introductory   \n",
            "1                                  Charles Severance  Introductory   \n",
            "2                 David J. Malan-Doug Lloyd-Brian Yu  Introductory   \n",
            "3  Dimitris Bertsimas-Allison O'Hair-John Silberh...  Intermediate   \n",
            "4                                     Stephan Sorger  Introductory   \n",
            "\n",
            "                        subject language subtitles         course_effort  \\\n",
            "0  Education & Teacher Training  English   English    2–3 hours per week   \n",
            "1              Computer Science  English   English    2–4 hours per week   \n",
            "2              Computer Science  English   English   6–18 hours per week   \n",
            "3    Data Analysis & Statistics  English   English  10–15 hours per week   \n",
            "4              Computer Science  English   English    5–7 hours per week   \n",
            "\n",
            "  course_length                                         price  \\\n",
            "0       2 Weeks   FREE-Add a Verified Certificate for $49 USD   \n",
            "1       7 Weeks   FREE-Add a Verified Certificate for $49 USD   \n",
            "2      12 Weeks   FREE-Add a Verified Certificate for $90 USD   \n",
            "3      13 Weeks  FREE-Add a Verified Certificate for $199 USD   \n",
            "4       4 Weeks  FREE-Add a Verified Certificate for $249 USD   \n",
            "\n",
            "                                  course_description  \\\n",
            "0  Designed for those who are new to elearning, t...   \n",
            "1  This course aims to teach everyone the basics ...   \n",
            "2  This is CS50x , Harvard University's introduct...   \n",
            "3  In the last decade, the amount of data availab...   \n",
            "4  Begin your journey in a new career in marketin...   \n",
            "\n",
            "                                     course_syllabus  \\\n",
            "0  Welcome - We start with opportunities to meet ...   \n",
            "1                                                NaN   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "\n",
            "                                          course_url  \n",
            "0     https://www.edx.org/course/how-to-learn-online  \n",
            "1  https://www.edx.org/course/programming-for-eve...  \n",
            "2  https://www.edx.org/course/cs50s-introduction-...  \n",
            "3      https://www.edx.org/course/the-analytics-edge  \n",
            "4  https://www.edx.org/course/marketing-analytics...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We checked the data"
      ],
      "metadata": {
        "id": "0z50yiauaxQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check missing values\n",
        "dfnew = df[features]\n",
        "df.isnull().sum()\n",
        "dfn = df[target]\n",
        "dfn.isnull().sum()"
      ],
      "metadata": {
        "id": "KEE4yxIiBl_V",
        "outputId": "fa44a205-0d2f-4a9d-97d5-cc9bba7d61d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- There were 120 Missing values in target variable -> 'n_enrolled'"
      ],
      "metadata": {
        "id": "k7Dmi-8fa10K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transform columns and fill Missing values in n_enrolled\n",
        "\n"
      ],
      "metadata": {
        "id": "a2qAEqKUBT-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values in 'n_enrolled' with 0 (assuming courses with no enrollment data have 0 enrollments)\n",
        "df['n_enrolled'] = df['n_enrolled'].str.replace(',', '').fillna(0).astype(int)\n",
        "\n",
        "# Continue with the rest of the data cleaning steps\n",
        "\n",
        "# Convert 'course_length' to numeric (extracting the number of weeks)\n",
        "df['course_length'] = df['course_length'].str.extract('(\\d+)').astype(float)\n",
        "\n",
        "# Extract the minimum effort per week from 'course_effort'\n",
        "df['course_effort'] = df['course_effort'].str.extract('(\\d+)').astype(float)\n",
        "\n",
        "\n",
        "# Extract the numeric part of 'price' (we'll use the price of the certificate if applicable)\n",
        "df['price'] = df['price'].str.extract('(\\d+)').astype(float)\n",
        "\n",
        "# Handle missing values in price (assume free for missing prices)\n",
        "df['price'].fillna(0, inplace=True)\n",
        "\n",
        "# encoding categoricals\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Apply Label Encoding to each column\n",
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "for column in ['Level', 'subject', 'course_type']:\n",
        "    df[column] = label_encoder.fit_transform(df[column])\n",
        "\n",
        "# Prepare feature set and target\n",
        "features = ['course_length', 'price', 'Level', 'subject', 'course_type']\n",
        "X = df[features]\n",
        "y = df['n_enrolled']\n",
        "\n",
        "# Check the cleaned dataset\n",
        "X.head(), y.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN0P0x2VOcv-",
        "outputId": "b2b0cbf8-6fea-415c-a6ab-5c6b3ac10ba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-be45a88e6af7>:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['price'].fillna(0, inplace=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   course_length  price  Level  subject  course_type\n",
              " 0            2.0   49.0      2       10            1\n",
              " 1            7.0   49.0      2        6            1\n",
              " 2           12.0   90.0      2        6            1\n",
              " 3           13.0  199.0      1        7            0\n",
              " 4            4.0  249.0      2        6            1,\n",
              " 0     124980\n",
              " 1     293864\n",
              " 2    2442271\n",
              " 3     129555\n",
              " 4      81140\n",
              " Name: n_enrolled, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We Transformed all feature variables and removed strings in them and then converted them to float."
      ],
      "metadata": {
        "id": "lDXvwv4pbCKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scale the data and apply Linear Regression"
      ],
      "metadata": {
        "id": "oeCuRv_1DMxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the feature variables\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "y_train_scaled = scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = scaler.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Initialize the Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model on the training set\n",
        "model.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model using Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test_scaled, y_pred)\n",
        "# Evaluate the Random Forest model using Mean Squared Error (MSE)\n",
        "lr_rmse = np.sqrt(mean_squared_error(y_test_scaled, y_pred))\n",
        "lr_r2 = r2_score(y_test_scaled,  y_pred)\n",
        "print(f\" RMSE: {lr_rmse}\")\n",
        "print(f\"R² Score: {lr_r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAggFhugOiJY",
        "outputId": "0142d99a-054a-4a35-8dfa-e63ae1c3c71f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " RMSE: 0.838433832665797\n",
            "R² Score: 0.07707709778831318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We scaled the data and then applied it to the Linear Regression as the ranges in each variable especially the target variable were too high.\n",
        "- We achieved high RMSE and low r2 score with Linear Regression showing its not a best fit."
      ],
      "metadata": {
        "id": "MLfjo5TjbPgy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scale the Data and Apply Random Forest Regression  and Decision Tree Regression"
      ],
      "metadata": {
        "id": "QHuq4qv4DRkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Initialize the Random Forest and Decision Tree models\n",
        "random_forest_model = RandomForestRegressor(random_state=42)\n",
        "decision_tree_model = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Train the Random Forest model on the training set\n",
        "random_forest_model.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "# Train the Decision Tree model on the training set\n",
        "decision_tree_model.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "# Make predictions using Random Forest\n",
        "rf_y_pred = random_forest_model.predict(X_test_scaled)\n",
        "\n",
        "# Make predictions using Decision Tree\n",
        "dt_y_pred = decision_tree_model.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "AAW2hKVKQfFL",
        "outputId": "db9891e6-fbc5-4060-f145-91b0aed585c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the Random Forest model using Root Mean Squared Error (MSE)\n",
        "rf_rmse = np.sqrt(mean_squared_error(y_test_scaled, rf_y_pred))\n",
        "rf_r2 = r2_score(y_test_scaled,  rf_y_pred)\n",
        "print(f\" RMSE: {rf_rmse}\")\n",
        "print(f\"R² Score: {rf_r2}\")"
      ],
      "metadata": {
        "id": "NZl5YVKIrNiw",
        "outputId": "f10cfcc7-7dae-4203-f901-166a28c32d33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " RMSE: 0.7654081763416066\n",
            "R² Score: 0.23084471592011546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Decision Tree model using Root Mean Squared Error (MSE)\n",
        "dt_mse = mean_squared_error(y_test_scaled, dt_y_pred)\n",
        "dt_r2 = r2_score(y_test_scaled, dt_y_pred)\n",
        "print(f\"Decision Tree MSE: {dt_mse}\")\n",
        "print(f\"Decision Tree r2: {dt_r2}\")"
      ],
      "metadata": {
        "id": "Y8HiWtHQrQAW",
        "outputId": "d37dac46-9ac3-4d52-f765-4b6533dea0f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree MSE: 1.8340234736653933\n",
            "Decision Tree r2: -1.4078682684253123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We achieved high RMSE and low r2 score with Random Forest and Decision Tree but Decision Tree performed poorly while Random Forest yeilded some level of accuracy in comparison to both decision tree and Linear Regression."
      ],
      "metadata": {
        "id": "WNs7W21eblzM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scale the Data and Apply XGboost"
      ],
      "metadata": {
        "id": "m2pRIDpHDhaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# XGBoost pipeline\n",
        "xgb_model = Pipeline(steps=[\n",
        "    (\"regressor\", XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "xgb_model.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "# Make predictions\n",
        "xgb_preds = xgb_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "xgb_rmse = np.sqrt(mean_squared_error(y_test_scaled, xgb_preds))\n",
        "xgb_r2 = r2_score(y_test_scaled, xgb_preds)\n",
        "print(f\"XGBoost RMSE: {xgb_rmse}\")\n",
        "print(f\"XGBoost R² Score: {xgb_r2}\")"
      ],
      "metadata": {
        "id": "eWl67GFjD9tO",
        "outputId": "18eac6b8-29da-4a15-e45d-66944a09c638",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost RMSE: 1.0151295592319989\n",
            "XGBoost R² Score: -0.3529158404233128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Gradient Boosting did not perform as well as we hoped as it yielded negative r2 score and high RMSE."
      ],
      "metadata": {
        "id": "ZhcCkEpMb3bC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scale the data and apply Neural Network"
      ],
      "metadata": {
        "id": "tp5myedfDqAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Neural Network model\n",
        "nn_model = Sequential([\n",
        "    Dense(128, activation=\"relu\", input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)  # Single output for regression\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "nn_model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\", metrics=[\"mse\"])\n",
        "\n",
        "# Train the model\n",
        "history = nn_model.fit(X_train_scaled, y_train_scaled, validation_split=0.2, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "# Make predictions\n",
        "nn_preds = nn_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "nn_rmse = np.sqrt(mean_squared_error(y_test_scaled, nn_preds))\n",
        "nn_r2 = r2_score(y_test_scaled, nn_preds)\n",
        "print(f\"Neural Network RMSE: {nn_rmse}\")\n",
        "print(f\"Neural Network R² Score: {nn_r2}\")"
      ],
      "metadata": {
        "id": "Hda3zKK3GKao",
        "outputId": "79a4a298-d7a8-4f2a-886b-8701dac7131e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Neural Network RMSE: 0.8175172579024549\n",
            "Neural Network R² Score: 0.12255138562003343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Nueral Networks performed better than all  other models but did not surpass Random Forest Regressor."
      ],
      "metadata": {
        "id": "gfrojCKLcEaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Model             | RMSE               | R² Score            |\n",
        "|-------------------|--------------------|---------------------|\n",
        "| Neural Network    | 0.8175172579024549 | 0.12255138562003343 |\n",
        "| XGBoost           | 1.0151295592319989 | -0.3529158404233128 |\n",
        "| Linear Regression | 0.838433832665797  | 0.07707709778831318 |\n",
        "| Random Forest     | 0.7654081763416066  | 0.23084471592011546 |\n",
        "| Decision Tree     | 1.8340234736653933 | -1.4078682684253123 |\n"
      ],
      "metadata": {
        "id": "suY7BhKvHTj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper Param Tuning for Decision Tree and Random Forest"
      ],
      "metadata": {
        "id": "F1tJg0vv5Ps2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# --- Random Forest Hyperparameter Tuning ---\n",
        "rf_params = {\n",
        "    'n_estimators': [50, 100, 200],            # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 20, 30],           # Maximum depth of each tree\n",
        "    'min_samples_split': [2, 5, 10],           # Minimum number of samples required to split\n",
        "    'min_samples_leaf': [1, 2, 4],             # Minimum number of samples per leaf\n",
        "    'bootstrap': [True, False]                 # Whether bootstrap samples are used\n",
        "}\n",
        "\n",
        "random_forest_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Perform Grid Search for Random Forest\n",
        "rf_grid = GridSearchCV(estimator=random_forest_model, param_grid=rf_params,\n",
        "                       scoring='neg_mean_squared_error', cv=5, verbose=2, n_jobs=-1)\n",
        "\n",
        "rf_grid.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "# Best parameters for Random Forest\n",
        "print(\"Best Random Forest Parameters:\", rf_grid.best_params_)\n",
        "\n",
        "# Evaluate the tuned Random Forest model\n",
        "rf_best_model = rf_grid.best_estimator_\n",
        "rf_y_pred = rf_best_model.predict(X_test_scaled)\n",
        "rf_mse = mean_squared_error(y_test_scaled, rf_y_pred)\n",
        "rf_r2 = r2_score(y_test_scaled, rf_y_pred)\n",
        "print(f\"Tuned Random Forest MSE: {rf_mse}\")\n",
        "print(f\"Tuned Random Forest r2: {rf_r2}\")\n",
        "\n",
        "# --- Decision Tree Hyperparameter Tuning ---\n",
        "dt_params = {\n",
        "    'max_depth': [None, 10, 20, 30],           # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5, 10],           # Minimum number of samples required to split\n",
        "    'min_samples_leaf': [1, 2, 4],             # Minimum number of samples per leaf\n",
        "    'criterion': ['squared_error', 'absolute_error']  # Splitting criteria\n",
        "}\n",
        "\n",
        "decision_tree_model = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Perform Grid Search for Decision Tree\n",
        "dt_grid = GridSearchCV(estimator=decision_tree_model, param_grid=dt_params,\n",
        "                       scoring='neg_mean_squared_error', cv=5, verbose=2, n_jobs=-1)\n",
        "\n",
        "dt_grid.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "# Best parameters for Decision Tree\n",
        "print(\"Best Decision Tree Parameters:\", dt_grid.best_params_)\n",
        "\n",
        "# Evaluate the tuned Decision Tree model\n",
        "dt_best_model = dt_grid.best_estimator_\n",
        "dt_y_pred = dt_best_model.predict(X_test_scaled)\n",
        "dt_mse = mean_squared_error(y_test_scaled, dt_y_pred)\n",
        "dt_r2 = r2_score(y_test_scaled, dt_y_pred)\n",
        "print(f\"Tuned Decision Tree MSE: {dt_mse}\")\n",
        "print(f\"Tuned Decision Tree r2: {dt_r2}\")"
      ],
      "metadata": {
        "id": "jJXRmqKN5QcI",
        "outputId": "9409345a-91a8-47e5-d733-32cd440eb636",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest Parameters: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}\n",
            "Tuned Random Forest MSE: 0.5231898084238092\n",
            "Tuned Decision Tree r2: 0.31311013399981913\n",
            "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
            "Best Decision Tree Parameters: {'criterion': 'absolute_error', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
            "Tuned Decision Tree MSE: 0.7137660890582013\n",
            "Tuned Decision Tree r2: 0.0629047329004706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We were able to slightly improve MSE and r2 score with Hyper parameter tuning where max depth was a vital factor in both and we could have further improved this if we had access to more computational resources."
      ],
      "metadata": {
        "id": "0cpMdVNpcNVR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Model              | Best Parameters                                                                                  | MSE               | r2 Score |\n",
        "|--------------------|------------------------------------------------------------------------------------------------|-------------------|-------------------|\n",
        "| Random Forest      | {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200} | 0.52 | 0.31 |\n",
        "| Decision Tree      | {'criterion': 'absolute_error', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10} | 0.71 | 0.06 |\n"
      ],
      "metadata": {
        "id": "SkygDzPzDoU8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply Diffusion model approach to existing models"
      ],
      "metadata": {
        "id": "P1zEgEBuEIRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "class DiffusionModeling:\n",
        "    def __init__(self, X_train, X_test, y_train, y_test):\n",
        "        # Ensure that data is in the correct format (numpy arrays)\n",
        "        X_train = np.array(X_train)\n",
        "        X_test = np.array(X_test)\n",
        "        y_train = np.array(y_train).reshape(-1, 1)  # Reshaping to 2D array\n",
        "        y_test = np.array(y_test).reshape(-1, 1)  # Reshaping to 2D array\n",
        "\n",
        "        # Scaling the independent features (X) and the target variable (y)\n",
        "        self.feature_scaler = StandardScaler()\n",
        "        self.target_scaler = StandardScaler()\n",
        "\n",
        "        # Scale independent features\n",
        "        self.X_train = self.feature_scaler.fit_transform(X_train)\n",
        "        self.X_test = self.feature_scaler.transform(X_test)\n",
        "\n",
        "        # Scale target variable\n",
        "        self.y_train = self.target_scaler.fit_transform(y_train)\n",
        "        self.y_test = self.target_scaler.transform(y_test)\n",
        "\n",
        "        self.models = {\n",
        "            \"Neural Network\": self._neural_network,\n",
        "            \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\n",
        "            \"Linear Regression\": LinearRegression(),\n",
        "            \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "            \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
        "        }\n",
        "        self.results = {}\n",
        "\n",
        "    def apply_diffusion(self, n_synthetic=1000):\n",
        "        # Create synthetic data\n",
        "        synthetic_X = np.random.normal(self.X_train.mean(axis=0), self.X_train.std(axis=0), size=(n_synthetic, self.X_train.shape[1]))\n",
        "        synthetic_y = np.random.normal(self.y_train.mean(), self.y_train.std(), size=n_synthetic).reshape(-1, 1)  # Reshaping to 2D\n",
        "\n",
        "        # Stack the synthetic data with the original data\n",
        "        self.X_train = np.vstack([self.X_train, synthetic_X])\n",
        "        self.y_train = np.vstack([self.y_train, synthetic_y])  # Ensure y_train is 2D\n",
        "\n",
        "    def evaluate_models(self):\n",
        "        for name, model in self.models.items():\n",
        "            if name == \"Neural Network\":\n",
        "                preds, mse, r2 = model()\n",
        "            else:\n",
        "                model.fit(self.X_train, self.y_train)\n",
        "                preds = model.predict(self.X_test)\n",
        "                mse = mean_squared_error(self.y_test, preds)\n",
        "                r2 = r2_score(self.y_test, preds)\n",
        "\n",
        "            self.results[name] = {\n",
        "                \"MSE\": mse,\n",
        "                \"R²\": r2\n",
        "            }\n",
        "\n",
        "    def _neural_network(self):\n",
        "        # Neural Network Model\n",
        "        model = Sequential([\n",
        "            Dense(64, activation=\"relu\", input_shape=(self.X_train.shape[1],)),\n",
        "            Dense(32, activation=\"relu\"),\n",
        "            Dense(1)\n",
        "        ])\n",
        "        model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(self.X_train, self.y_train, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "        # Predictions and evaluation\n",
        "        preds = model.predict(self.X_test).flatten()\n",
        "        mse = mean_squared_error(self.y_test, preds)\n",
        "        r2 = r2_score(self.y_test, preds)\n",
        "        return preds, mse, r2\n",
        "\n",
        "    def display_results(self):\n",
        "        print(\"| Model             | MSE               | R² Score            |\")\n",
        "        print(\"|-------------------|--------------------|---------------------|\")\n",
        "        for name, metrics in self.results.items():\n",
        "            print(f\"| {name:<17} | {metrics['MSE']:<18} | {metrics['R²']:<20} |\")\n",
        "\n",
        "# Example usage with preprocessed data (replace with actual dataset)\n",
        "# X_train, X_test, y_train, y_test should be prepared before this step\n",
        "# Ensure that X_train, X_test, y_train, y_test are numpy arrays (or properly converted from pandas DataFrames/Series)\n",
        "diffusion_model = DiffusionModeling(X_train, X_test, y_train, y_test)\n",
        "diffusion_model.apply_diffusion()\n",
        "diffusion_model.evaluate_models()\n",
        "diffusion_model.display_results()"
      ],
      "metadata": {
        "id": "RS-9Gg5qOmrL",
        "outputId": "b080afcb-14d4-4c4a-88cf-63bcaa179c9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Model             | MSE               | R² Score            |\n",
            "|-------------------|--------------------|---------------------|\n",
            "| Neural Network    | 0.7722477566664627 | -0.01387517408572525 |\n",
            "| XGBoost           | 0.49583239694288234 | 0.34902736404460555  |\n",
            "| Linear Regression | 0.7228698261861444 | 0.050952541410440366 |\n",
            "| Random Forest     | 0.5020833049634731 | 0.3408206189904951   |\n",
            "| Decision Tree     | 0.7741825650174489 | -0.01641536165732349 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- After a diffusion Model approach where we add synthetic data to increase the model's ability to capture data trends, we saw it improved XGBOOST and Random Forest but worsened other models."
      ],
      "metadata": {
        "id": "WSQv72BAchpp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenges"
      ],
      "metadata": {
        "id": "BM_unqhodIfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Limited computational resources.\n",
        "- Limited data.\n",
        "- We did not have a Pakistan platform specific dataset which is why we used Edx to create a proof of cocnept for education platforms in Pakistan who we noted may have similar variables for their online course marketplaces."
      ],
      "metadata": {
        "id": "eSx5hFwSdLii"
      }
    }
  ]
}